{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9283a322",
   "metadata": {},
   "outputs": [],
   "source": [
    "# in this notebook we compute the variance explained\n",
    "# by the linear sparce PCA and the SDP sparce pca\n",
    "# in a various datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f655c27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# to compute the variance explained, we follow the paper\n",
    "#\"https://www.sciencedirect.com/science/article/pii/S0169743919303636\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85309f6e",
   "metadata": {},
   "source": [
    "<h1>functions and evaluation of explained variance by the SDP for sparse PCA  and its linear relaxation<h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78793233",
   "metadata": {},
   "source": [
    "<h1>Table of contents <h1>   \n",
    "    0.    Load packages, load sparsePCArelaxations notebook, Functions.<br>\n",
    "    1. Code for figure 5 <br>\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3fd280b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "db386835",
   "metadata": {},
   "source": [
    "<h2>0.  Load packages, load sparsePCArelaxations notebook, Functions.<h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2a1b1059",
   "metadata": {},
   "outputs": [],
   "source": [
    "using RDatasets, NBInclude, MultivariateStats, StatsBase\n",
    "using Statistics,  Plots, DataFrames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fc6bd618",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "EigenRelSparsePCA (generic function with 1 method)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@nbinclude(\"sparsePCArelaxations.ipynb\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48f29433",
   "metadata": {},
   "source": [
    "<h3>Functions<h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bdde6bb0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "computeVarianceSDP (generic function with 1 method)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#function to compute the variance explained by sparse PCAs computed using the semidefinite relaxation.\n",
    "# k is a vector where k[i] is the target sparcity of pc i. Length of k is the number of PCs.\n",
    "#@param int k: the target sparcity.\n",
    "#@param dataframe data:  the data set to be used.\n",
    "#@param bool normalize: variable that indicates if we should normalize the data or not. \n",
    "#@returns the variance explained by the SDP, as computed in\n",
    "# https://www.sciencedirect.com/science/article/pii/S0169743919303636\"\n",
    "\n",
    "function computeVarianceSDP(k,data,normalize::Bool)\n",
    "#currentCovMatrix = cor(data)    \n",
    "  n = size(data)[1]   \n",
    "    \n",
    "  if normalize == true\n",
    "    \n",
    "    currentCovMatrix = (1/(n-1))* scattermat(data) \n",
    "        \n",
    "    else\n",
    "        currentCovMatrix = scattermat(data) \n",
    "    end    \n",
    "    \n",
    "    dims = size(currentCovMatrix)[1]\n",
    "     \n",
    "numPc = length(k)   \n",
    "#sdp \n",
    "  SdpSol=SdpSparsePCA(currentCovMatrix,k[1])[1]\n",
    "currentPc =eigen(SdpSol).vectors[:,dims]\n",
    "PCs = currentPc  \n",
    " currentCovMatrix = currentCovMatrix-(transpose(currentPc)*currentCovMatrix*currentPc)*currentPc*transpose(currentPc)\n",
    " for i in 2:numPc\n",
    "     \n",
    "SdpSol=SdpSparsePCA(currentCovMatrix,k[i])[1]        \n",
    "currentPc =eigen(SdpSol).vectors[:,dims] \n",
    "PCs = hcat(PCs,currentPc) \n",
    "    \n",
    "currentCovMatrix = currentCovMatrix-(transpose(currentPc)*currentCovMatrix*currentPc)*currentPc*transpose(currentPc)    \n",
    "    end\n",
    "    \n",
    "PCs= round.(PCs,digits=4)\n",
    " That = data*PCs*pinv(transpose(PCs)*PCs) \n",
    "    \n",
    "   # return(That)\n",
    "VarianceExplained = tr(PCs*transpose(That)*That*transpose(PCs))/tr(data*transpose(data))\n",
    "   \n",
    " return(VarianceExplained)   \n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "aa65f629",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "computeVarianceLP (generic function with 1 method)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#function to compute the variance explained by sparse PCAs computed using the linear relaxation.\n",
    "# k is a vector where k[i] is the target sparcity of pc i. Length of k is the number of PCs.\n",
    "#@param int k the target sparcity .\n",
    "#@param dataframe data: is the data set to be used.\n",
    "#@param bool normalize: variable indicates if we should normalize the data or not. \n",
    "#@returns the variance explained by the LP, as computed in\n",
    "# https://www.sciencedirect.com/science/article/pii/S0169743919303636\"\n",
    "function computeVarianceLP(k,data,normalize::Bool)\n",
    "#currentCovMatrix = cor(data)\n",
    " n = size(data)[1]   \n",
    " \n",
    "    if normalize == true\n",
    "    \n",
    "    currentCovMatrix = (1/(n-1))* scattermat(data) \n",
    "        \n",
    "    else\n",
    "        currentCovMatrix = scattermat(data) \n",
    "    end\n",
    "        \n",
    "dims = size(currentCovMatrix)[1]\n",
    "numPc = length(k)   \n",
    "#sdp \n",
    "  lpSol=EigenRelSparsePCA(currentCovMatrix,k[1])[1]\n",
    "currentPc =eigen(lpSol).vectors[:,dims]\n",
    "PCs = currentPc\n",
    " \n",
    " currentCovMatrix = currentCovMatrix-(transpose(currentPc)*currentCovMatrix*currentPc)*currentPc*transpose(currentPc)\n",
    " for i in 2:numPc\n",
    "     \n",
    "lpSol=EigenRelSparsePCA(currentCovMatrix,k[i])[1]        \n",
    "currentPc =eigen(lpSol).vectors[:,dims] \n",
    "PCs = hcat(PCs,currentPc) \n",
    "    \n",
    "currentCovMatrix = currentCovMatrix-(transpose(currentPc)*currentCovMatrix*currentPc)*currentPc*transpose(currentPc)    \n",
    "    end\n",
    "    \n",
    "PCs= round.(PCs,digits=4)\n",
    " That = data*PCs*pinv(transpose(PCs)*PCs) \n",
    "    \n",
    "   # return(That)\n",
    "VarianceExplained = tr(PCs*transpose(That)*That*transpose(PCs))/tr(data*transpose(data))\n",
    "   \n",
    " return(VarianceExplained)   \n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9aeebe41",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "processDataset (generic function with 1 method)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fucntion to curate the datasets we will use, and keep only the real variables.\n",
    "#@param int min_number_covariates: the minimum number of real covariates that the dataset must contain.\n",
    "# if the number of covariantes in a dataset is less than this number, the dataset is discarded.\n",
    "# @param int max_number_covariates: the maximum number of covariates to consider.\n",
    "function processDataset(min_number_covariates,max_number_covariates)\n",
    "    \n",
    "    datas =  RDatasets.datasets()\n",
    "    num_data_tables = size(datas)[1]\n",
    "    datas[!,:num_float_vars]= zeros(size(datas)[1])\n",
    "\n",
    "      \n",
    "for i in 1:  num_data_tables\n",
    "        \n",
    "     currentTable = dataset(datas[i,1], datas[i,2])\n",
    "     currentTable = select(currentTable, findall(col -> eltype(col) <: Float64, eachcol(currentTable)))\n",
    "      datas[i,size(datas)[2]]= size(currentTable)[2]   \n",
    "     end\n",
    "    \n",
    "  datas =  datas[datas.num_float_vars .> min_number_covariates, :]\n",
    "   datas = datas[datas.num_float_vars .<=max_number_covariates,:]\n",
    "\n",
    "    \n",
    "    return(datas)\n",
    "end\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "44d93c49",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "explained_variances (generic function with 1 method)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# function to give the value of the variance explained, fixing\n",
    "# the same vectors for both the SDP and the LP.\n",
    "#@param string datasetName : name of the dataset to use.\n",
    "#@param string tableName: name of the table to use.\n",
    "#@param vector sparcityPatern: the i-th entry of sparcityPatern corresponds to the target.\n",
    "#@param sparcity of the i-th component.\n",
    "#@param bool normalize: indicates if we should normalize the data or not. \n",
    "function give_variances(datasetName::String,tableName::String,sparcityPatern,normalize::Bool)\n",
    "   \n",
    "    num_Pcs = length(sparcityPatern) \n",
    "    \n",
    "    dat = dataset(datasetName, tableName)\n",
    "    dat = select(dat, findall(col -> eltype(col) <: Float64, eachcol(dat)))\n",
    "    dat =Matrix(dat)    \n",
    "    \n",
    "    #Careful, for the pca, observations must be in columns. For our methods, our observations\n",
    "    # are in rows. Also, the fit function regularizes the matrix by default\n",
    "    \n",
    "    # normalize the data\n",
    "    dat = mapslices(x -> x.-mean(x), dat, dims=1)\n",
    "    \n",
    "    dat_for_normal_PCA = transpose(dat)\n",
    "    totalVarExplainedPCA = principalratio(fit(PCA,iris2Reg,maxoutdim=num_Pcs)) \n",
    "     return( computeVarianceLP(sparcityPatern,dat,normalize),  computeVarianceSDP(sparcityPatern,dat),totalVarExplainedPCA)\n",
    "end\n",
    "\n",
    "\n",
    "#function to return the best variance explained found by altering the sparcity target. \n",
    "#@param string datasetName : name of the dataset to use.\n",
    "#@param string tableName: name of the table to use.\n",
    " #@param bool normalize: indicates if we should normalize the data or not. \n",
    "function findBestKoneComponent(datasetName::String,tableName::String,normalize::Bool)\n",
    "   \n",
    "    dat = dataset(datasetName, tableName)\n",
    "    dat = select(dat, findall(col -> eltype(col) <: Float64, eachcol(dat)))\n",
    "    dat =Matrix(dat)\n",
    "    dat = mapslices(x -> x.-mean(x), dat, dims=1)\n",
    "\n",
    "    numVars = size(dat)[2]\n",
    "    max_sparcity = Int64(floor(numVars/2))+1\n",
    "    bestLP = 0\n",
    "    bestSDP = 0\n",
    "    \n",
    "    #compute the pca explained variance\n",
    "    \n",
    "    \n",
    "    dat_for_normal_PCA = transpose(dat)\n",
    "    totalVarExplainedPCA = principalratio(fit(PCA,dat_for_normal_PCA,maxoutdim=1)) \n",
    "    \n",
    "    \n",
    "      for i in 1:max_sparcity\n",
    "        bestLP = max(bestLP, computeVarianceLP([i,i,i,i],dat,normalize))\n",
    "        bestSDP =  max(bestSDP, computeVarianceSDP([i,i,i,i],dat,normalize))\n",
    "    end\n",
    "    return(bestLP,bestSDP,totalVarExplainedPCA)\n",
    "end\n",
    "\n",
    "\n",
    "\n",
    "#function to plot the best variance explained against different datasets\n",
    "# we take p datasets of the RDatasets, with at least 10 variables.\n",
    "# param dataSet dataset containing the names of tables to be used to computes variance explained\n",
    "# by the pca, SDP sparce plca and LP sparce PCA.\n",
    "# We assume dataSet was selected using the processDataset function.\n",
    "function explained_variances(dataSet::Any)\n",
    "    \n",
    "    number_tables, number_cols= size(dataSet)\n",
    "    \n",
    "    computed_variances = zeros(number_tables,3)\n",
    "    \n",
    "     \n",
    "    for i in 1: number_tables\n",
    " \n",
    "   computed_variances[i,:] .=  findBestKoneComponent(String(dataSet[i,1]),String(dataSet[i,2]),false)\n",
    "    end \n",
    "   return(computed_variances)  \n",
    "\n",
    "end\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "123d1009",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2d631a15",
   "metadata": {},
   "source": [
    "<h2>    1. Code for figure 5 <h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4253a0df",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Warning: Dropped duplicate factor levels\n",
      "└ @ RData C:\\Users\\danis\\.julia\\packages\\RData\\OT7M6\\src\\convert.jl:118\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div class=\"data-frame\"><p>11 rows × 6 columns (omitted printing of 3 columns)</p><table class=\"data-frame\"><thead><tr><th></th><th>Package</th><th>Dataset</th><th>Title</th></tr><tr><th></th><th title=\"InlineStrings.String15\">String15</th><th title=\"InlineStrings.String31\">String31</th><th title=\"String\">String</th></tr></thead><tbody><tr><th>1</th><td>Ecdat</td><td>Forward</td><td>Exchange Rates of US Dollar Against Other Currencies</td></tr><tr><th>2</th><td>Ecdat</td><td>Klein</td><td>Klein&apos;s Model I</td></tr><tr><th>3</th><td>Ecdat</td><td>MedExp</td><td>Structure of Demand for Medical Care</td></tr><tr><th>4</th><td>HSAUR</td><td>pottery</td><td>Romano-British Pottery Data</td></tr><tr><th>5</th><td>MASS</td><td>fgl</td><td>Measurements of Forensic Glass Fragments</td></tr><tr><th>6</th><td>mlmRev</td><td>bdf</td><td>Language Scores of 8-Graders in The Netherlands</td></tr><tr><th>7</th><td>psych</td><td>Holzinger.9</td><td>Seven data sets showing a bifactor solution.</td></tr><tr><th>8</th><td>psych</td><td>Thurstone.33</td><td>Seven data sets showing a bifactor solution.</td></tr><tr><th>9</th><td>psych</td><td>Thurstone</td><td>Seven data sets showing a bifactor solution.</td></tr><tr><th>10</th><td>psych</td><td>Tucker</td><td>9 Cognitive variables discussed by Tucker and Lewis (1973)</td></tr><tr><th>11</th><td>sem</td><td>Klein</td><td>Klein&apos;s Data on the U. S. Economy</td></tr></tbody></table></div>"
      ],
      "text/latex": [
       "\\begin{tabular}{r|cccc}\n",
       "\t& Package & Dataset & Title & \\\\\n",
       "\t\\hline\n",
       "\t& String15 & String31 & String & \\\\\n",
       "\t\\hline\n",
       "\t1 & Ecdat & Forward & Exchange Rates of US Dollar Against Other Currencies & $\\dots$ \\\\\n",
       "\t2 & Ecdat & Klein & Klein's Model I & $\\dots$ \\\\\n",
       "\t3 & Ecdat & MedExp & Structure of Demand for Medical Care & $\\dots$ \\\\\n",
       "\t4 & HSAUR & pottery & Romano-British Pottery Data & $\\dots$ \\\\\n",
       "\t5 & MASS & fgl & Measurements of Forensic Glass Fragments & $\\dots$ \\\\\n",
       "\t6 & mlmRev & bdf & Language Scores of 8-Graders in The Netherlands & $\\dots$ \\\\\n",
       "\t7 & psych & Holzinger.9 & Seven data sets showing a bifactor solution. & $\\dots$ \\\\\n",
       "\t8 & psych & Thurstone.33 & Seven data sets showing a bifactor solution. & $\\dots$ \\\\\n",
       "\t9 & psych & Thurstone & Seven data sets showing a bifactor solution. & $\\dots$ \\\\\n",
       "\t10 & psych & Tucker & 9 Cognitive variables discussed by Tucker and Lewis (1973) & $\\dots$ \\\\\n",
       "\t11 & sem & Klein & Klein's Data on the U. S. Economy & $\\dots$ \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/plain": [
       "\u001b[1m11×6 DataFrame\u001b[0m\n",
       "\u001b[1m Row \u001b[0m│\u001b[1m Package  \u001b[0m\u001b[1m Dataset      \u001b[0m\u001b[1m Title                             \u001b[0m\u001b[1m Rows  \u001b[0m\u001b[1m Colum\u001b[0m ⋯\n",
       "\u001b[1m     \u001b[0m│\u001b[90m String15 \u001b[0m\u001b[90m String31     \u001b[0m\u001b[90m String                            \u001b[0m\u001b[90m Int64 \u001b[0m\u001b[90m Int64\u001b[0m ⋯\n",
       "─────┼──────────────────────────────────────────────────────────────────────────\n",
       "   1 │ Ecdat     Forward       Exchange Rates of US Dollar Agai…    276        ⋯\n",
       "   2 │ Ecdat     Klein         Klein's Model I                       22\n",
       "   3 │ Ecdat     MedExp        Structure of Demand for Medical …   5574\n",
       "   4 │ HSAUR     pottery       Romano-British Pottery Data           45\n",
       "   5 │ MASS      fgl           Measurements of Forensic Glass F…    214        ⋯\n",
       "   6 │ mlmRev    bdf           Language Scores of 8-Graders in …   2287\n",
       "   7 │ psych     Holzinger.9   Seven data sets showing a bifact…      9\n",
       "   8 │ psych     Thurstone.33  Seven data sets showing a bifact…      9\n",
       "   9 │ psych     Thurstone     Seven data sets showing a bifact…      9        ⋯\n",
       "  10 │ psych     Tucker        9 Cognitive variables discussed …      9\n",
       "  11 │ sem       Klein         Klein's Data on the U. S. Economy     22\n",
       "\u001b[36m                                                               2 columns omitted\u001b[0m"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# first select the datasets to use. We want between 8 and 20 float64 covariates.\n",
    "datasets_to_use = processDataset(8,20)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d718c96c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#compute the variances explained in each dataset.\n",
    "variances_results = explained_variances(datasets_to_use)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73dd4b86",
   "metadata": {},
   "outputs": [],
   "source": [
    "#take the name of each dataset to use as label\n",
    "labelsx = datasets_to_use.Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb903f72",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot the results.\n",
    "variancesDifferencesnopca = zeros(40)\n",
    "for i in 1:40\n",
    "    variancesDifferencesnopca[i] =100*(variances_results[i,2]-variances_results[i,1])/variances_results[i,2]\n",
    "end\n",
    "plot(scatter(variancesDifferencesnopca,xticks=(1:40,labelsx),xrotation = 90,labels=\"Percentual_error\",markershape = :diamond,markercolor = :black,legend=:topleft))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.7.3",
   "language": "julia",
   "name": "julia-1.7"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
